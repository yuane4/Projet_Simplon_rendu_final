{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sources = pd.read_excel('Sources.xlsx', encoding='latin-1')\n",
    "df_991 = pd.read_excel('99-1.xlsx', encoding='latin-1')\n",
    "df_199 = pd.read_excel('1-99.xlsx', encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((207596,), (102250,), (207596,), (102250,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "#on divise l'échantillon en train et test \n",
    "X = df_sources['Adresses']\n",
    "y = df_sources['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modèle Naives Bayes en Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((207596, 49636), (102250, 49636))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "#on vectorize les données a étudier afin d'être comprise par le modèle\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train.astype('U'))\n",
    "X_test_counts = count_vect.transform(X_test.astype('U'))\n",
    "X_train_counts.shape, X_test_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       1.00      0.99      0.99     67636\n",
      "     adresse       0.98      0.99      0.99     34614\n",
      "\n",
      "    accuracy                           0.99    102250\n",
      "   macro avg       0.99      0.99      0.99    102250\n",
      "weighted avg       0.99      0.99      0.99    102250\n",
      "\n",
      "accuracy of the model is : 0.990317848410758\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics #on imprime les métrics d'évaluations\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rajout de poids probabiliste en TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((207596, 49636), (102250, 49636))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "#afin d'afiner le modèle, on instaur eun systèe de poids probabilitste en Tf -IDF\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "X_train_tf.shape, X_test_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Naîve Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tf, y_train)\n",
    "y_pred = clf.predict(X_test_tf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       1.00      0.99      0.99     67636\n",
      "     adresse       0.98      0.99      0.99     34614\n",
      "\n",
      "    accuracy                           0.99    102250\n",
      "   macro avg       0.99      0.99      0.99    102250\n",
      "weighted avg       0.99      0.99      0.99    102250\n",
      "\n",
      "accuracy of the model is : 0.9907677261613692\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred,  target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Lr = LogisticRegression(random_state=0, max_iter = 100, solver = 'newton-cg')\n",
    "Lr.fit(X_train_tf, y_train)\n",
    "y_pred = Lr.predict(X_test_tf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       0.99      1.00      0.99     67636\n",
      "     adresse       1.00      0.98      0.99     34614\n",
      "\n",
      "    accuracy                           0.99    102250\n",
      "   macro avg       0.99      0.99      0.99    102250\n",
      "weighted avg       0.99      0.99      0.99    102250\n",
      "\n",
      "accuracy of the model is : 0.9915012224938875\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Rf = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "Rf.fit(X_train_tf, y_train)\n",
    "y_pred = Rf.predict(X_test_tf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       0.66      1.00      0.80     67636\n",
      "     adresse       1.00      0.01      0.02     34614\n",
      "\n",
      "    accuracy                           0.67    102250\n",
      "   macro avg       0.83      0.51      0.41    102250\n",
      "weighted avg       0.78      0.67      0.54    102250\n",
      "\n",
      "accuracy of the model is : 0.665760391198044\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On change de dataset avec une répartion 99% adresses 1% de bruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67000,), (33001,), (67000,), (33001,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "#on divise l'échantillon en train et test \n",
    "X = df_991['Adresses']\n",
    "y = df_991['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67000, 35458), (33001, 35458))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #on vectorize les données a étudier afin d'être comprise par le modèle\n",
    "count_vect = CountVectorizer()\n",
    "X_tr991_counts = count_vect.fit_transform(X_train.astype('U'))\n",
    "X_te991_counts = count_vect.transform(X_test.astype('U'))\n",
    "X_tr991_counts.shape, X_te991_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha =  0.00001, fit_prior = True) #alpha = 1.2 fit_prior = False\n",
    "# clf = MultinomialNB()\n",
    "clf.fit(X_tr991_counts, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_te991_counts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       1.00      0.34      0.51       296\n",
      "     adresse       0.99      1.00      1.00     32705\n",
      "\n",
      "    accuracy                           0.99     33001\n",
      "   macro avg       1.00      0.67      0.75     33001\n",
      "weighted avg       0.99      0.99      0.99     33001\n",
      "\n",
      "accuracy of the model is : 0.9940607860367867\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics #on imprime les métrics d'évaluations\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67000, 35458), (33001, 35458))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer #afin d'afiner le modèle, on instaur eun systèe de poids probabilitste en Tf -IDF\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_tr991_counts)\n",
    "X_tr991_tf = tf_transformer.transform(X_tr991_counts)\n",
    "X_te991_tf = tf_transformer.transform(X_te991_counts)\n",
    "X_tr991_tf.shape, X_te991_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha =  0.00001, fit_prior = True) #alpha = 1.2 fit_prior = False\n",
    "# clf = MultinomialNB()\n",
    "clf.fit(X_tr991_tf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_te991_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       0.99      0.34      0.51       296\n",
      "     adresse       0.99      1.00      1.00     32705\n",
      "\n",
      "    accuracy                           0.99     33001\n",
      "   macro avg       0.99      0.67      0.75     33001\n",
      "weighted avg       0.99      0.99      0.99     33001\n",
      "\n",
      "accuracy of the model is : 0.9940607860367867\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics #on imprime les métrics d'évaluations\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Regression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Lr = LogisticRegression(random_state=0)\n",
    "Lr.fit(X_tr991_tf, y_train)\n",
    "y_pred = Lr.predict(X_te991_tf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       1.00      0.31      0.48       296\n",
      "     adresse       0.99      1.00      1.00     32705\n",
      "\n",
      "    accuracy                           0.99     33001\n",
      "   macro avg       1.00      0.66      0.74     33001\n",
      "weighted avg       0.99      0.99      0.99     33001\n",
      "\n",
      "accuracy of the model is : 0.9938486712523863\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Rf = RandomForestClassifier(max_depth=10, random_state=0, n_estimators=100)\n",
    "Rf.fit(X_tr991_tf, y_train)\n",
    "y_pred = Rf.predict(X_te991_tf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       1.00      0.01      0.01       296\n",
      "     adresse       0.99      1.00      1.00     32705\n",
      "\n",
      "    accuracy                           0.99     33001\n",
      "   macro avg       1.00      0.50      0.50     33001\n",
      "weighted avg       0.99      0.99      0.99     33001\n",
      "\n",
      "accuracy of the model is : 0.9910911790551802\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On change de dataset avec une répartion 1% adresses 99% de bruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((66999,), (33000,), (66999,), (33000,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "#on divise l'échantillon en train et test \n",
    "X = df_199['Adresses']\n",
    "y = df_199['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((66999, 16477), (33000, 16477))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #on vectorize les données a étudier afin d'être comprise par le modèle\n",
    "count_vect = CountVectorizer()\n",
    "X_tr199_counts = count_vect.fit_transform(X_train.astype('U'))\n",
    "X_te199_counts = count_vect.transform(X_test.astype('U'))\n",
    "X_tr199_counts.shape, X_te199_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Naïve Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_tr199_counts , y_train)\n",
    "\n",
    "y_pred = clf.predict(X_te199_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       1.00      1.00      1.00     32685\n",
      "     adresse       1.00      0.88      0.94       315\n",
      "\n",
      "    accuracy                           1.00     33000\n",
      "   macro avg       1.00      0.94      0.97     33000\n",
      "weighted avg       1.00      1.00      1.00     33000\n",
      "\n",
      "accuracy of the model is : 0.9988484848484849\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Regression logistique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Lr = LogisticRegression(random_state=0)\n",
    "Lr.fit(X_tr199_counts, y_train)\n",
    "y_pred = Lr.predict(X_te199_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       1.00      1.00      1.00     32685\n",
      "     adresse       1.00      0.72      0.84       315\n",
      "\n",
      "    accuracy                           1.00     33000\n",
      "   macro avg       1.00      0.86      0.92     33000\n",
      "weighted avg       1.00      1.00      1.00     33000\n",
      "\n",
      "accuracy of the model is : 0.9973030303030304\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Rf = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "Rf.fit(X_tr199_counts, y_train)\n",
    "y_pred = Rf.predict(X_te199_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       0.99      1.00      1.00     32685\n",
      "     adresse       0.00      0.00      0.00       315\n",
      "\n",
      "    accuracy                           0.99     33000\n",
      "   macro avg       0.50      0.50      0.50     33000\n",
      "weighted avg       0.98      0.99      0.99     33000\n",
      "\n",
      "accuracy of the model is : 0.9904545454545455\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names, zero_division = 0))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement sur une répartition 50 -50 et 1 millionss de lignes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- chargement des données : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ad = pd.read_csv('adresses_50_50.csv', encoding='utf-8', sep = ';')\n",
    "df_bruit = pd.read_excel('bruit.xlsx', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_50_50 = pd.concat([df_ad, df_bruit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_50_50=sklearn.utils.shuffle(df_50_50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((683004,), (336406,), (683004,), (336406,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "#on divise l'échantillon en train et test \n",
    "X = df_50_50['Adresses']\n",
    "y = df_50_50['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((683004, 250341), (336406, 250341))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "#on vectorize les données a étudier afin d'être comprise par le modèle\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train.astype('U'))\n",
    "X_test_counts = count_vect.transform(X_test.astype('U'))\n",
    "X_train_counts.shape, X_test_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((683004, 250341), (336406, 250341))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "#afin d'afiner le modèle, on instaur eun systèe de poids probabilitste en Tf -IDF\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "X_train_tf.shape, X_test_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics #on imprime les métrics d'évaluations\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 62186, 103565],\n",
       "       [     0, 170655]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.99325337 0.99333536 0.99358133 0.99338222 0.99355791 0.99345242\n",
      " 0.99298389 0.99298381]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = X_train_tf\n",
    "y = y_train\n",
    "\n",
    "scores = cross_val_score(MultinomialNB(), X, y, cv=8)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Lr = LogisticRegression(random_state=0, max_iter = 100, solver = 'newton-cg')\n",
    "Lr.fit(X_train_tf, y_train)\n",
    "y_pred = Lr.predict(X_test_tf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       1.00      1.00      1.00    165751\n",
      "     adresse       1.00      1.00      1.00    170655\n",
      "\n",
      "    accuracy                           1.00    336406\n",
      "   macro avg       1.00      1.00      1.00    336406\n",
      "weighted avg       1.00      1.00      1.00    336406\n",
      "\n",
      "accuracy of the model is : 0.9989893164806811\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics #on imprime les métrics d'évaluations\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165625,    126],\n",
       "       [   214, 170441]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.99887556 0.99862959 0.99885214 0.99887556 0.99877015 0.99889898\n",
      " 0.99869985 0.99880526]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = X_train_tf\n",
    "y = y_train\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(random_state=0, max_iter = 100, solver = 'newton-cg'), X, y, cv=8)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Rf = RandomForestClassifier(max_depth=8, random_state=0, n_estimators = 200)\n",
    "Rf.fit(X_train_tf, y_train)\n",
    "y_pred = Rf.predict(X_test_tf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bruit       0.99      0.99      0.99    165751\n",
      "     adresse       0.99      0.99      0.99    170655\n",
      "\n",
      "    accuracy                           0.99    336406\n",
      "   macro avg       0.99      0.99      0.99    336406\n",
      "weighted avg       0.99      0.99      0.99    336406\n",
      "\n",
      "accuracy of the model is : 0.9896494117227398\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics #on imprime les métrics d'évaluations\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[159151,   6600],\n",
       "       [ 12999, 157656]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.97788606 0.96978073 0.96417026 0.95382777 0.95174288 0.9621552\n",
      " 0.96600878 0.96794106]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = X_train_tf\n",
    "y = y_train\n",
    "\n",
    "scores = cross_val_score(RandomForestClassifier(max_depth=8, random_state=0, n_estimators = 100), X, y, cv=8)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rf.pkl']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf, 'nbm.pkl') \n",
    "joblib.dump(Lr, 'Lr.pkl') \n",
    "joblib.dump(Rf, 'Rf.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_991\n",
    "# df_199\n",
    "\n",
    "X = df_991['Adresses']\n",
    "y = df_991['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309846, 56569), (309846,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(X.astype('U'))\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "\n",
    "X_tf = tf_transformer.transform(X_train_counts)\n",
    "X_tf.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1242da2260bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# load the model from disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nbm.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\LOGICIELS\\Anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\LOGICIELS\\Anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[1;32mC:\\LOGICIELS\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1081\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1083\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# load the model from disk\n",
    "\n",
    "nbm = joblib.load(\"nbm.pkl\")\n",
    "y_pred = nbm.predict(X_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics #on imprime les métrics d'évaluations\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "target_names = ['bruit', 'adresse']\n",
    "print(metrics.classification_report(y, y_pred, target_names=target_names))\n",
    "print(\"accuracy of the model is :\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
